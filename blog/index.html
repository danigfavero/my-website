<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>Blog</title>

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600;700&display=swap" rel="stylesheet">        
        <link rel="stylesheet" href="../css/styles.css">
        <link rel="stylesheet" href="../css/blog.css">
        <link rel="icon" type="image/png" href="../img/favicon.png"/>
    </head>

    <body>
        <header>
        <ul>
            <li class="header-text"><a class="header-link" href="../">Home</a></li>
            <li class="header-text"><a class="header-link" href="../mac0499">TCC</a></li>
            <li class="header-text header-text--clicked"><a class="header-link" href="">Blog</a></li>
        </ul>
        </header>

        <!-- Olá, você está lendo meu código horrível e deve ter notado que está tudo 
            hardcodado. Junte minha falta de vontade de fazer um servidorzinho pra mexer
            com AJAX e meu ódio ao Medium; e obtenha este blog mal-feito porém funcional.
            Viva a gambiarra :-) -->
            <!-- Hello, you're reading my horrible code and may have noticed that's all
            hardcoded. Put together my lack of will in building a mini-server to deal with
            AJAX and my hatred towards Medium: the result is this poorly made, yet
            functional blog. Long live the gambiarra :-) -->
        <div class="post">
            <h1>"Diversidade e Representatividade na Computação"</h1>
            <p class="subtitle">Resumos de alguns textos sobre o assunto e notas pessoais com o que compreendi em minha leitura.</p>
            <div class="author">Escrito por Daniela Favero em 07/12/2020</div>
            <img class="post-img" src="../img/woman-in-tech-ime-usp.jpg"/>
            <p class="description">Primeira turma de formados no curso de Ciência da Computação do IME/USP, em 1974, na qual as mulheres eram a maioria.</p>

            <h2>Cultural stereotypes as gatekeepers: increasing girls’ interest in computer science and engineering by diversifying stereotypes</h2>
            <p>Este artigo é sobre como os <b>estereótipos</b> podem ser barreiras para mulheres se aproximarem das ciências exatas. A autora começa mostrando o problema que tem ocorrido: <b>menos de 20%</b> dos diplomas de ciência da computação e engenharia vão para mulheres. A partir daí, ela parte para uma investigação do motivo que tem separado as mulheres da computação, porque, aparentemente, elas estão <b>livremente não escolhendo</b> seguir ciência da computação.</p>
            <p>Dentre os motivos mencionados para mulheres não seguirem essas carreiras, estão: pais, professores e outros têm afastados essas mulheres pensando que são carreiras <b>melhores para homens</b>; a <b>sub-representação</b> na área desmotiva outras mulheres a escolher a carreira, perpetuando a sub-representação; garotas <b>sistematicamente subestimam</b> o quão bem elas vão se performar nesses campos; o medo da <b>discriminação</b> por ser minoria na área (mulheres que entram em domínios tradicionalmente masculinos podem ser socialmente e profissionalmente penalizadas por mostrar competência e qualidades de liderança).</p>
            <p>Os motivos citados acima decorrem da <b>sub-representação</b> feminina na computação, que, por sua vez, surge a partir dos estereótipos sobre a cultura desses campos, como sobre o <b>tipo de pesso</b> neles (socialmente isolados, focados em tecnologia), sobre o <b>trabalho</b> (não colaborativo) ou sobre os <b>valores</b> (interesses masculinos, “genialidade”); além dos estereótipos sobre as <b>habilidades femininas</b>, que seriam menores que as masculinas (e que não se encaixariam nas ciências exatas). Essas noções chegam muito cedo nas mulheres, afetando meninas de <b>ensino médio</b> a não se sentirem aptas a entrar nesses campos.</p>
            <p>Depois disso, a autora cita as três maneiras como esses estereótipos são <b>transmitidos</b>: pelo <b>ambiente</b> (uma série de pesquisas mostrou como ambientes contendo o estereótipo <i>“nerd”</i> gerava uma sensação de não-pertencimento nas mulheres), a <b>mídia</b> (como séries e o retrato da cultura de <i>start-up</i>) e as próprias pessoas nesses campos (que por muitas vezes acabam por confirmar o estereótipo). No entanto, é importante apontar que as pesquisas que evidenciaram os problemas que os estereótipos geram, também mostrou que uma certa parcela de mulheres e a maioria dos homens se sente <b>confortável com os estereótipos</b>, sentindo maior <b>pertencimento</b> à área.</p>
            <p>Dadas as <b>evidências empíricas</b> de que esses estereótipos causam disparidades de gênero no interesse em seguir ciência da computação e engenharia, a autora conclui que os estereótipos atuais devem ser <b>diversificados, não eliminados</b>. Desde o ensino médio, é importante mostrar como o retrato do engenheiro ou cientista da computação é <b>variável</b>, ampliando a representação cultural nessas áreas. Na prática, os departamentos de ciência da computação da </i>Carnegie Mellon</i> e da <i>Harvey Mudd</i> conseguiram aumentar a proporção de mulheres se formando em ciência da computação de cerca de <b>10% para 40% em 5 anos</b>, aplicando mudanças estruturais e modificando o estereótipo dos profissionais da área.</p>
            <h3>Notas pessoais:</h3>
            <p>Esse texto é excelente e deu voz às muitas mulheres da computação com essa sensação de não-pertencimento à área da computação. De fato o estereótipo de <i>nerd</i> genial que “sonha em código” é de certa forma tóxico para mulheres (e homens que não se encaixam no estereótipo), podendo gerar síndrome de impostor nessas pessoas. Acima de tudo, a sugestão do texto de diversificar a imagem do cientista da computação é excelente; e concordo que essa quebra de estereótipo deve ser mais enfatizada no ensino médio, época em que as meninas decidem qual carreira irão seguir.</p>

            <h2>Como as mulheres passaram de maioria a raridade nos cursos de informática (BBC)</h2>
            <p>Esta reportagem da <b>BBC</b> aborda o tema da diminuição das mulheres em cursos de informática. Menciona-se que, nos seus <b>primórdios</b>, os computadores eram usados basicamente para realizar cálculos e processamento de dados, atividades então associadas à <b>função de secretária</b>. Por isso, o início da ciência da computação contou com diversas mulheres para construir suas bases, dentre elas <b>Ada Lovelace</b> (a criadora do primeiro algoritmo) e <b>Grace Hopper</b> (a criadora do primeiro compilador).</p>
            <p><b>Até 1990</b>, as mulheres eram predominantes em cursos de informática. Acredita-se que esse interesse das mulheres pela graduação nessa área tenha relação com o <b>curso de Matemática e licenciatura em Matemática</b> (que sempre foi predominantemente feminino). <b>Entre 1990 e 2000</b>, a proporção de gêneros <b>se equilibrou</b> e a partir de <b>2000</b> a quantidade delas <b>foi caindo</b> ano a ano. No Brasil, segundo a Pesquisa Nacional por Amostra de Domicílios (Pnad), do <b>IBGE</b>, elas representam apenas <b>20%</b> dos mais de 580 mil profissionais da área de tecnologia da informação.</p>
            <p>A diminuição de mulheres na área acompanhou a ascensão da <b>importância econômica</b> que a computação obteve a partir da década de 80: <b>após 1984</b>, foram lançados os primeiros computadores com materiais de divulgação <b>voltados para o público masculino</b>, começando, assim, um desinteresse das mulheres. Quando a computação deixa de ser um <b>trabalho braçal</b> e repetitivo, para passar a ser um <b>trabalho intelectual</b> e lógico, criou-se um estereótipo de que homens seriam mais adequados para a área. Além de tudo isso, atemporalmente, mulheres são <b>pouco incentivadas para as áreas de exatas</b> nos ensinos fundamental e médio, aprendendo a preferir brincar de <b>boneca</b> (associada a profissões de cuidadores, como enfermeiros) em vez de <b><i>videogames</i></b> (associados a carreiras de tecnologia).</p>
            <h3>Notas Pessoais:</h3>
            <p>A reportagem da BBC ilustra claramente o cenário exposto no primeiro artigo: como um estereótipo diminuiu expressivamente a quantidade de mulheres na computação. Mais assustador ainda: a área costumava ser repleta de mulheres, mas o aumento da importância econômica da área ajudou a promover a programação como uma atividade masculina. Pelo lado positivo, a história mostra que o perfil dos profissionais da computação é maleável e, assim como, nos anos 80 os homens se tornaram maioria na área, se nos esforçarmos para mudar a imagem do cientista da computação, conseguiremos balancear a proporção de gênero na área. Acima de tudo, a história também mostra que computação não é uma profissão masculina — ela começou nas mãos e mentes de mulheres.</p>

            <h2>Bibliografia</h2>
            <ol>
                <li><span class=bib><b>Cultural stereotypes as gatekeepers: increasing girls’ interest in computer science and engineering by diversifying stereotypes.</b> Disponível em: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4323745" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4323745</a></span></li>
                <li><span class=bib><b>Como as mulheres passaram de maioria a raridade nos cursos de informática.</b> Disponível em: <a href="https://www.bbc.com/portuguese/geral-43592581" target="_blank">https://www.bbc.com/portuguese/geral-43592581</a></span></li>
            </ol>
        </div>

        <div class="post">
            <h1>"Accountability e Transparência — O Direito a Explicações"</h1>
            <p class="subtitle">Resumos de alguns textos sobre o assunto e notas pessoais com o que compreendi em minha leitura.</p>
            <div class="author">Escrito por Daniela Favero em 21/10/2020</div>
            <img class="post-img" src="../img/code-projected-on-woman.jpeg"/>
            <p class="description">Imagem: Unsplash / @thisisengineering</p>

            <h2>Ananny M and Crawford K, ‘Seeing without Knowing: Limitations of the Transparency Ideal and Its Application to Algorithmic Accountability’. New Media & Society.</h2>
            <p>Este primeiro texto começa com uma contextualização histórica da transparência. Ele aponta o nascimento da valorização da transparência durante o Iluminismo (séculos XVII e XVIII) e como o conceito de transparência foi deixando de ser apenas performativo — sempre positivo, de modo a produzir entendimento — e passou a mostrar aspectos mais práticos. Alguns teóricos mencionavam a necessidade de um sistema de observação e conhecimento que prometeria uma forma de controle para obter plena transparência.</p>
            <p>Depois disso, surgem classificações tipológicas sobre o tema, dentre elas transparência <i>fuzzy</i> e <i>clear</i> (quanto ao nível de divulgação de informações), <i>accountability soft</i> e <i>hard</i> (a respeito de como órgãos transparentes devem responder por suas ações), transparência <i>upwards</i> e <i>downwards</i> (que diz respeito à hierarquia), transparência como processo e evento (sobre o formato), e, finalmente, transparência em retrospecto e tempo-real (considerando temporalidade).</p>
            <p>Ainda contextualizando, o texto traz à tona as importantes discussões atuais contidas em movimentos como hacktivismo e <i>open source</i>, além de organizações como a Wikipédia. Também é citada a preocupação com as possíveis discriminações algorítmicas em programas amplamente usados na sociedade.</p>
            <p>Toda essa discussão historicamente relevante sobre a transparência culmina numa definição de limites ideais para tal conceito. Os limites citados no texto são: a possibilidade da transparência estar desconectada do poder, a ameaça da privacidade, a obstrução intencional (quando há uma grande carga de informação que pode distrair o público do que realmente importa), criação de falsos binários, evocação de modelos neoliberais (valorizando a maximização do poder individual e minimização da interferência governamental), o fato de que transparência não necessariamente constrói confiança (questionando a ética do público que tem acesso às informações divulgadas), a possibilidade de se privilegiar o ver sobre o entender, as limitações técnicas e limitações temporais.</p>
            <p>O debate caminha para a questão: transparência é uma forma adequada de governar sistemas algorítmicos? Os autores do texto concluem que não, porque em contextos digitais, transparência não é só sobre revelar informações ou manter segredos; mas sobre continuamente manter plataformas, algoritmos e protocolos de <i>machine learning</i> que permitem visibilidade.</p>
            <p>Apesar de ser uma discussão meramente teórica, aqueles limites ideais encontram uso como ferramentas para guiar o modelo de transparência e <i>accountability</i> de quem administra sistemas algorítmicos. Além, conclui-se que transparência não é só sobre deixar o algoritmo e os dados utilizados visíveis, mas sim sobre ter responsabilidade sobre a composição do sistema; afinal, na prática, é mais importante ter uma visão através do sistema (examinando a relação entre as parte humanas e não-humanas) do que uma simples visão dentro dele.</p>
            <h3>Notas pessoais:</h3>
            <p>Esse texto é excelente e realmente me fez pensar sobre os limites da transparência e sobre como ela pode ser distorcida dependendo dos argumentos e intenções de quem a impõe. Deste modo, a transparência isolada não faz sentido além de ferramenta teórica para a imposição de limites (conforme citado no texto). É aí que surge a necessidade da <i>accountability</i>, a importância de se criar <i>softwares</i> responsáveis pelas decisões tomadas e que se debruçam sobre os impactos sociais do mesmo.</p>
        
            <h2>Burrell J., How the machine “thinks”: Understanding opacity in machine learning algorithms. Big Data & Society.</h2>
            <p>Este texto começa com a definição de opacidade: dados o <i>input</i> e o <i>output</i> não fica claro como foi feita uma classificação em particular. Além disso, nem sempre os <i>inputs</i> são totalmente conhecidos. Esse fenômeno ocorre com alta frequência em algoritmos de <i>machine learning</i>.</p>
            <p>A autora define três formas de opacidade: a intencional pela corporação ou por segredo de Estado, a falta de instrução técnica e a forma como algoritmos operam em escala de aplicação. A primeira é dita como essencial para a autoproteção desses órgãos, mas se revela cada mais nociva na prática com escândalos de abuso de privacidade. Esta seria facilmente resolvível com <i>open source</i>, permitindo que qualquer um (com o conhecimento técnico necessário) acesse o código fonte e compreenda as implementações.</p>
            <p>A falta de instrução técnica pode se resolver com educação acessível sobre algoritmos, dado que a cada dia se torna mais necessário conhecer o funcionamento destes para ser um cidadão esclarecido. A própria autora se utiliza de boa parte do texto para explicar o funcionamento de algoritmos de <i>machine learning</i> como redes neurais e SVM (<i>support vector machine</i>), cumprindo o papel do cientista de divulgar seu trabalho e tornar o conhecimento democrático.</p>
            <p>Finalmente, o problema da escalabilidade se dá pelo fato de que quanto mais dados de entrada, mais acurados ficam os sistemas de <i>machine learning</i>, mas também maior a complexidade dos mesmos. Apesar de haver uma certa intuição sobre como os dados se relacionam com os resultados em escalas menores, os classificadores (peça fundamental dos algoritmos de <i>machine learning</i>) se tornam cada vez menos interpretáveis conforme treinamos o programa com dados mais heterogêneos.</p>
            <p>As três sugestões que a autora dá para resolver este último problema são: parar de usar <i>machine learning</i> em contextos críticos (o que é um tanto extremado), se utilizar de <i>feature extraction</i> (remover os parâmetros do algoritmo que possam levar a algum tipo de discriminação) ou criar métricas para avaliar discriminação nas classificações que o programa fez.</p>
            <h3>Notas pessoais:</h3>
            <p>Na minha opinião, os dois primeiros problemas de transparência para algoritmos podem ser respectivamente resolvidos com <i>open source</i> e educação, bem como a própria autora menciona no texto. Uma nota sobre <i>open source</i>, é que tornar um sistema secreto não o torna mais seguro, segundo vários profissionais de segurança da informação (como pode se ler <a href="https://www.zdnet.com/article/six-open-source-security-myths-debunked-and-eight-real-challenges-to-consider/" target="_blank">aqui</a>). Não conhecia as possibilidades de se visualizar um sistema feito com <i>machine learning</i>, a explicação foi muito interessante e acredito que, mesmo que seja custoso computacionalmente, <i>softwares</i> que tomam decisões que impactarão na sociedade devem ser explicáveis.</p>

            <h2>Bibal A et al., ‘Legal Requirements on Explainability in Machine Learning’. Artificial Intelligence and Law.</h2>
            <p>Neste artigo, os autores começam contrapondo os conceitos de interpretabilidade — quando um modelo é compreensível por natureza, como árvores de decisão — e de explicabilidade — dado pela capacidade de explicar um modelo caixa-preta usando recursos externos, como a visualização.</p>
            <p>A partir disto, o artigo aborda os requerimentos legais que utilizarão esses conceitos, particularmente em relação à <i>General Data Protection Regulation</i> (GDPR) da União Europeia. Os requerimentos pediriam especificações sobre quem toma as decisões em um sistema e qual é o grau de automação no processo de tomada de decisão; afinal erros e vieses podem ter efeitos muito maiores na tomada de decisões feita por IA do que por humanos. Assim, esses requerimentos permitiriam que os afetados por uma decisão entendam sua justificativa e ajam de acordo, além de permitirem que a autoridade pública exerça controle efetivo significativo na legalidade da decisão.</p>
            <p>O texto ainda divide várias modalidades de requerimentos legais, em situações como B2B (<i>business-to-business</i>), B2C (<i>business-to-consumer</i>) — com suas respectivas leis horizontais. Também são cobertas regras setoriais, com legislações específicas para setores como o financeiro e o de seguro. Ainda, conclui-se que em relações G2C (<i>government-to-citizens</i>), a explicabilidade precisa ser ainda mais forte.</p>
            <p>Depois disso, constata-se que há diferentes níveis de explicabilidade, de modo que em alguns níveis, o requerimento é relativo ao modelo do sistema, enquanto que em outros é relativo à decisão tomada a partir do sistema.</p>
            <p>O primeiro nível é o dos requerimentos das <i>features</i> principais, que se dá a partir da obtenção dos parâmetros principais usados numa determinada decisão ou no modelo em si. O único porém deste nível é que o procedimento de <i>feature extraction</i>, que seria necessário para extrair os parâmetros mais relevantes do modelo, é computacionalmente difícil.</p>
            <p>O segundo nível é dos requerimentos de todas as <i>features</i> (ou todas que fazem parte do caminho tomado na árvore de decisão) processadas no modelo. O problema deste nível é que o tamanho do conjunto de <i>features</i> pode ser enorme, portanto muito complexo. Uma forma de resolver a alta complexidade dos dados, é fazer um trade-off entre acurácia e complexidade, dispondo aproximações boas o suficiente das <i>features</i> reais.</p>
            <p>Já o terceiro nível se dá pelos requerimentos da combinação de <i>features</i> numa decisão, o que é muito interessante porque oferece a completa explicação de decisões específicas do modelo (as justificativas em si). O problema é que para se conseguir essas combinações, é necessário que o modelo usado no sistema seja transparente (como árvores de decisão ou modelos lineares).</p>
            <p>Finalmente, o quarto nível é o dos requerimentos do modelo inteiro, desde que seja um modelo interpretável.</p>
            <p>Além disso, em casos de decisões administrativas, é necessário que os modelos forneçam os artigos da lei por trás de cada decisão. Neste contexto, uma situação descrita por fatos é fornecida como input para o modelo, juntamente com argumentos textuais de ambos os lados opostos. Deste modo, podem haver três tipos de dados de entrada para o modelo: fatos, artigos legais e argumentos. O texto descreve como se deve proceder em relação a cada possível <i>input</i>.</p>
            <h3>Notas pessoais:</h3>
            <p>As ideias apresentadas no texto são todas novas para mim e, ao meu ver, são juridicamente justas levando em conta análises mais teóricas e computacionais feitas nos dois textos anteriores (aliás esse diálogo entre os três textos é muito interessante, eles de fato se complementam nessas três áreas). Tive que pesquisar melhor sobre requerimentos e agora o conceito está um pouco mais claro.</p>

            <h2>FAT-ML Working Group,Principles for Accountable Algorithms and a Social Impact Statement for Algorithms.</h2>
            <p>Este texto é apenas uma lista de princípios para o desenvolvimento de algoritmos com <i>accountability</i>, e guias para aplicá-los. Os princípios são: responsabilidade (deve haver alguém responsável por revisar o sistema seus impactos sociais), explicabilidade (o modelo deve ser compreensível em termos não técnicos), acurácia (os dados devem ser acurados de modo a não causarem efeitos sociais negativos e, se não forem acurados, deve haver uma forma de mitigar as discrepâncias), auditabilidade (deve ser possível que outros possam revisar e questionar decisões do sistema, além de que devem haver termos de uso permissíveis) e justiça (garantir que não haja discriminação).</p>
            <p>No <i>"Social Impact Statement”</i>, o guia para aplicar esses princípios, o texto adiciona que para garantir que eles estejam sendo cumpridos, é necessário checá-los durante do estágio de <i>design</i>, pré-lançamento e pós-lançamento (este último tornando o <i>Statement</i> público). O texto ainda especifica exemplos para construir o <i>Social Impact Statement</i> para determinado sistema.</p>
            <h3>Notas pessoais:</h3>
            <p>Assim como do lado jurídico (apresentado no texto do A. Bibal), há o lado dos desenvolvedores de <i>software</i> para garantir <i>accountability</i> nos sistemas. O guia apresentado é bem sucinto e seus exemplos práticos clarificam como devem ser aplicados. Na minha opinião, o <i>Social Impact Statement</i> deveria ser uma exigência para <i>softwares</i> que tomarão decisões que impactarão na sociedade.</p>

            <h2>Bibliografia</h2>
            <ol>
                <li><span class=bib>Ananny M and Crawford K, <b>‘Seeing without Knowing: Limitations of the Transparency Ideal and Its Application to Algorithmic Accountability’.</b> New Media & Society. Disponível em: <a href="http://mike.ananny.org/papers/anannyCrawford_seeingWithoutKnowing_2016.pdf" target="_blank">http://mike.ananny.org/papers/anannyCrawford_seeingWithoutKnowing_2016.pdf</a></span></li>
                <li><span class=bib>Burrell J., <b>How the machine “thinks”: Understanding opacity in machine learning algorithms.</b> Big Data & Society.</span></li>
                <li><span class=bib>Bibal A et al., <b>Legal Requirements on Explainability in Machine Learning’.</b> Artificial Intelligence and Law. Disponível em: <a href="https://link.springer.com/article/10.1007/s10506-020-09270-4" target="_blank">https://link.springer.com/article/10.1007/s10506-020-09270-4</a></span></li>
                <li><span class=bib>AT-ML Working Group, <b>Principles for Accountable Algorithms and a Social Impact Statement for Algorithms.</b> Disponível em: <a href="http://www.fatml.org/resources/principles-for-accountable-algorithms" target="_blank">http://www.fatml.org/resources/principles-for-accountable-algorithms</a></span></li>
            </ol>

        </div>

        <footer>
            <ul>
                <li class="social">
                    <a href="http://github.com/danigfavero" target="_blank">
                        <img class="icon" src="../img/github.png" onmouseover="this.src='../img/github-orange.png';" onmouseout="this.src='../img/github.png';"/>
                    </a>
                </li>
                <li class="social">
                    <a href="http://linkedin.com/in/danigfavero" target="_blank">
                        <img class="icon" src="../img/linkedin.png" onmouseover="this.src='../img/linkedin-orange.png';" onmouseout="this.src='../img/linkedin.png';"/>
                    </a>
                </li>
                <li class="social">
                    <a href="http://lattes.cnpq.br/4380746598220062" target="_blank">
                        <img class="icon" src="../img/lattes.png" onmouseover="this.src='../img/lattes-orange.png';" onmouseout="this.src='../img/lattes.png';"/>
                    </a>
                </li>
            </ul>
            <p class="copyright">Feito com ♥ por Daniela Favero</p>
        </footer>
    </body>

</html>
